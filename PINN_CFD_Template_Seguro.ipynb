{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3445fdaa",
   "metadata": {},
   "source": [
    "\n",
    "# Template: PINN + Curvas de CFD (genérico e seguro)\n",
    "\n",
    "> **Objetivo:** fornecer uma **pipeline genérica** para integrar **curvas de CFD** externas (por ex., `condição × coeficientes`) em um **modelo físico‑informado** (PINN) com **varredura de parâmetros** e **otimização multiobjetivo**.  \n",
    "> **Uso previsto:** aplicações **civis/educacionais** (p. ex., perfis aerodinâmicos genéricos, pás de turbina, geometrias de dutos).  \n",
    ">\n",
    "> ⚠️ **Não use este caderno para armamentos.** O conteúdo é estritamente educacional em domínios inofensivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7098b411",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup do ambiente\n",
    "\n",
    "- Requer Python 3.9+ e PyTorch 2.x\n",
    "- Instalação sugerida:\n",
    "```bash\n",
    "conda create -n pinn-cfd python=3.10 -y\n",
    "conda activate pinn-cfd\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "pip install numpy pandas matplotlib tqdm pydantic\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea27e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, json, math, random, time, pathlib\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "try:\n",
    "    from tqdm import trange\n",
    "    _HAS_TQDM = True\n",
    "except Exception:\n",
    "    _HAS_TQDM = False\n",
    "\n",
    "print('Torch:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b1009",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Entrada de **curvas de CFD** (externas)\n",
    "\n",
    "Esperado um ou mais CSVs (ou DataFrames) com colunas como:\n",
    "- `condicao` (ex.: número de Mach, Reynolds, ângulo de ataque etc.)\n",
    "- `Cd` (coeficiente de arrasto) — opcional\n",
    "- `Cl` (coeficiente de sustentação) — opcional\n",
    "- `Cm` (coeficiente de momento) — opcional\n",
    "\n",
    "Adapte os nomes conforme suas curvas. O código abaixo mostra **exemplos de leitura**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exemplo: leitura de CSV ===\n",
    "# Substitua 'path/to/...' pelos seus arquivos. Você pode carregar múltiplos conjuntos.\n",
    "# Se estiver no Jupyter, arraste o CSV para a pasta de trabalho e atualize o caminho.\n",
    "paths = {\n",
    "    'dataset_1': 'path/to/curvas_cfd_1.csv',  # <- troque\n",
    "    # 'dataset_2': 'path/to/curvas_cfd_2.csv',\n",
    "}\n",
    "\n",
    "def load_cfd_curves(paths_dict):\n",
    "    dfs = {}\n",
    "    for name, p in paths_dict.items():\n",
    "        if not os.path.exists(p):\n",
    "            print(f\"[AVISO] Arquivo não encontrado: {p}. Pule ou atualize o caminho.\")\n",
    "            continue\n",
    "        df = pd.read_csv(p)\n",
    "        dfs[name] = df\n",
    "    return dfs\n",
    "\n",
    "cfd_data = load_cfd_curves(paths)\n",
    "list(cfd_data.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800aa310",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Pré‑processamento e normalização\n",
    "\n",
    "- Seleciona colunas de interesse e normaliza para melhorar o treinamento.\n",
    "- Se houver múltiplos datasets (regiões de operação), eles serão concatenados com uma tag de origem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14798a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolha as colunas que você realmente tem:\n",
    "feature_cols = ['condicao']            # ex.: ['Mach'] ou ['Re', 'AoA']\n",
    "target_cols  = ['Cd', 'Cl', 'Cm']      # deixe só o que tiver, e.g. ['Cd']\n",
    "\n",
    "def build_dataset(cfd_dict, feature_cols, target_cols):\n",
    "    frames = []\n",
    "    for name, df in cfd_dict.items():\n",
    "        # Filtra colunas disponíveis\n",
    "        keep = [c for c in feature_cols + target_cols if c in df.columns]\n",
    "        sub = df[keep].copy()\n",
    "        sub['__src__'] = name\n",
    "        frames.append(sub)\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"Nenhum dataset carregado. Atualize os caminhos/colunas.\")\n",
    "    full = pd.concat(frames, ignore_index=True)\n",
    "    # Normalização simples [0,1] por coluna\n",
    "    stats = {}\n",
    "    for c in feature_cols + target_cols:\n",
    "        if c in full.columns:\n",
    "            cmin, cmax = float(full[c].min()), float(full[c].max())\n",
    "            if cmax == cmin:\n",
    "                cmax = cmin + 1e-6\n",
    "            stats[c] = {'min': cmin, 'max': cmax}\n",
    "            full[c + '_norm'] = (full[c] - cmin) / (cmax - cmin)\n",
    "    return full, stats\n",
    "\n",
    "if cfd_data:\n",
    "    df_all, norm_stats = build_dataset(cfd_data, feature_cols, target_cols)\n",
    "    display(df_all.head())\n",
    "    print(json.dumps(norm_stats, indent=2))\n",
    "else:\n",
    "    df_all, norm_stats = None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e313ba4",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Parâmetros de **projeto genéricos** (geometria)\n",
    "\n",
    "Defina um **vetor de projeto** \\(\\mathbf{p}\\) com limites inferiores/superiores.  \n",
    "> *Exemplos civis*: parâmetros de um perfil aerodinâmico genérico (espessura, camber, razão de aspecto), canal de escoamento etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo seguro de parâmetros de projeto:\n",
    "design_space = {\n",
    "    'espessura':  (0.05, 0.20),   # valores adimensionais [min, max]\n",
    "    'camber':     (0.00, 0.10),\n",
    "    'razao_aspecto': (2.0, 8.0),\n",
    "}\n",
    "\n",
    "def sample_design(n=1):\n",
    "    xs = []\n",
    "    for _ in range(n):\n",
    "        p = {k: np.random.uniform(v[0], v[1]) for k, v in design_space.items()}\n",
    "        xs.append(p)\n",
    "    return xs\n",
    "\n",
    "sample_design(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211795e",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Modelo PINN (surrogate físico‑informado)\n",
    "\n",
    "- Entrada: **(parâmetros de projeto, condição de operação)** normalizados  \n",
    "- Saída: **coeficientes** (ex.: `Cd`, `Cl`, `Cm`) normalizados\n",
    "- *Loss* = **dados (curvas CFD)** + **termo físico** (restrições genéricas) + **regularizações**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc287c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, width=256, depth=6):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [in_dim] + [width]*depth + [out_dim]\n",
    "        for i in range(len(dims)-2):\n",
    "            layers += [nn.Linear(dims[i], dims[i+1]), nn.Tanh()]\n",
    "        layers += [nn.Linear(dims[-2], dims[-1])]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        # Xavier init\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Helper: normalização/denormalização\n",
    "def norm(x, stats):  # x: dict\n",
    "    out = {}\n",
    "    for k, v in x.items():\n",
    "        mn, mx = stats[k]['min'], stats[k]['max']\n",
    "        out[k+'_norm'] = (v - mn)/(mx - mn + 1e-12)\n",
    "    return out\n",
    "\n",
    "def denorm_vec(y, cols, stats):\n",
    "    y = y.clone().detach().cpu().numpy()\n",
    "    out = {}\n",
    "    for i, c in enumerate(cols):\n",
    "        if c in stats:\n",
    "            mn, mx = stats[c]['min'], stats[c]['max']\n",
    "            out[c] = y[:, i]*(mx - mn) + mn\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fcface",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1) **Termo físico genérico** (placeholders)\n",
    "\n",
    "Como o termo físico depende do problema seguro escolhido, deixamos **ganchos** exemplificativos:\n",
    "\n",
    "- **Suavidade** das curvas (penaliza derivadas muito grandes).\n",
    "- **Monotonicidade** opcional (p.ex., `Cd` crescente em determinada faixa).\n",
    "- **Limites físicos** (coeficientes em intervalos plausíveis).\n",
    "\n",
    "Adapte as funções abaixo ao seu domínio **não bélico**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_penalty(outputs, inputs, cols_out, lam_smooth=1e-3, lam_bounds=1e-3, bounds=None):\n",
    "    \"\"\" \n",
    "    outputs: tensor (N, O) normalizado\n",
    "    inputs:  tensor (N, D)  normalizado (últimas colunas podem ser condições)\n",
    "    cols_out: lista com nomes dos targets na mesma ordem da rede\n",
    "    bounds: dict opcional com limites *desnormalizados* por variável\n",
    "    \"\"\"\n",
    "    loss = torch.tensor(0.0, device=outputs.device)\n",
    "    # Suavidade via variação total aproximada\n",
    "    diff = outputs[1:] - outputs[:-1]\n",
    "    loss = loss + lam_smooth * torch.mean(diff**2)\n",
    "\n",
    "    # Limites físicos (se fornecidos)\n",
    "    if bounds is not None:\n",
    "        for j, name in enumerate(cols_out):\n",
    "            if name in bounds:\n",
    "                lo, hi = bounds[name]\n",
    "                # Converte limites p/ espaço normalizado ~ heurístico\n",
    "                # Se stats não estiver disponível aqui, aplique bounds no espaço real externamente.\n",
    "                # Aqui mantemos um \"clamp loss\" simples como placeholder.\n",
    "                loss = loss + lam_bounds * torch.mean(torch.relu(outputs[:, j] - 1.2))  # >1 (~fora do [0,1])\n",
    "                loss = loss + lam_bounds * torch.mean(torch.relu(0.0 - outputs[:, j]))  # <0\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527641b7",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Montagem do dataset e treino\n",
    "\n",
    "- **X** = concatenação de **parâmetros de projeto** (amostrados) + **condições** das curvas de CFD.  \n",
    "- **Y** = coeficientes alvos (a partir das curvas).  \n",
    "- Treinaremos um **surrogate físico‑informado** para prever os coeficientes em novas combinações (projeto, condição).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos tensores (exemplo)\n",
    "if df_all is not None:\n",
    "    # Features = [design params (amostrados)] + [condições do CFD]\n",
    "    n_design = 256  # quantidade de amostras de projeto para combinar\n",
    "    designs = sample_design(n_design)\n",
    "\n",
    "    # Expande condições do CFD para cada design\n",
    "    feats = []\n",
    "    tgts  = []\n",
    "    src_cols = [c for c in feature_cols if c+'_norm' in df_all.columns]\n",
    "    out_cols = [c for c in target_cols  if c+'_norm' in df_all.columns]\n",
    "\n",
    "    for p in designs:\n",
    "        # Normaliza projeto em [0,1] com limites do design_space\n",
    "        p_norm = {k+'_norm': (p[k]-design_space[k][0])/(design_space[k][1]-design_space[k][0]) for k in design_space}\n",
    "        P = pd.DataFrame([p_norm]*len(df_all))\n",
    "\n",
    "        feats.append(pd.concat([P.reset_index(drop=True), df_all[[c+'_norm' for c in src_cols]].reset_index(drop=True)], axis=1))\n",
    "        tgts.append(df_all[[c+'_norm' for c in out_cols]].reset_index(drop=True))\n",
    "\n",
    "    X_df = pd.concat(feats, ignore_index=True)\n",
    "    Y_df = pd.concat(tgts,  ignore_index=True)\n",
    "\n",
    "    X = torch.tensor(X_df.values, dtype=torch.float32, device=device)\n",
    "    Y = torch.tensor(Y_df.values, dtype=torch.float32, device=device)\n",
    "    print('X shape:', X.shape, '| Y shape:', Y.shape)\n",
    "else:\n",
    "    X = Y = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f388b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino (Adam) com termo de física genérico\n",
    "def train_surrogate(X, Y, in_dim, out_dim, epochs=20000, lr=1e-3, width=256, depth=6, log_every=1000):\n",
    "    model = MLP(in_dim, out_dim, width=width, depth=depth).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    hist = []\n",
    "    iterator = trange(epochs, desc='Treino', leave=False) if _HAS_TQDM else range(epochs)\n",
    "    for it in iterator:\n",
    "        opt.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss_data = torch.mean((pred - Y)**2)\n",
    "        loss_phys = physics_penalty(pred, X, cols_out=[c for c in Y_df.columns])\n",
    "        loss = loss_data + loss_phys\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if (it+1) % log_every == 0 or it == 0 or it == epochs-1:\n",
    "            hist.append({'iter': it+1, 'loss': float(loss.detach().cpu()),\n",
    "                         'data': float(loss_data.detach().cpu()),\n",
    "                         'phys': float(loss_phys.detach().cpu())})\n",
    "            if not _HAS_TQDM:\n",
    "                print(hist[-1])\n",
    "    return model, hist\n",
    "\n",
    "if X is not None:\n",
    "    model, history = train_surrogate(X, Y, in_dim=X.shape[1], out_dim=Y.shape[1], epochs=20000, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc746b",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Função objetivo (multiobjetivo → escalar)\n",
    "\n",
    "Defina **o que otimizar** (aplicação segura). Ex.: minimizar `Cd` médio e manter `Cl` próximo de um alvo; penalizar `Cm` fora de faixa.  \n",
    "Use uma **agregação escalar** (soma ponderada) ou um algoritmo multiobjetivo (ex.: NSGA‑II). Abaixo, mostramos a abordagem simples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de objetivo seguro (ajuste conforme seu caso)\n",
    "def objective_scalar(pred_metrics, w_cd=1.0, w_cl=0.1, cl_target=0.0, w_cm=0.1):\n",
    "    # pred_metrics: dict com arrays (em espaço real) para chaves presentes\n",
    "    score = 0.0\n",
    "    if 'Cd' in pred_metrics:\n",
    "        score += w_cd * float(np.mean(pred_metrics['Cd']))\n",
    "    if 'Cl' in pred_metrics:\n",
    "        score += w_cl * float(np.mean((pred_metrics['Cl'] - cl_target)**2))\n",
    "    if 'Cm' in pred_metrics:\n",
    "        score += w_cm * float(np.mean(np.maximum(0.0, np.abs(pred_metrics['Cm']) - 0.1)))  # faixa de estabilidade genérica\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da0cf5",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Varredura de projetos (até 1000 modelos/rodadas)\n",
    "\n",
    "- **Duas camadas** de varredura possíveis:\n",
    "  1. **Hiperparâmetros** do surrogate (largura, profundidade, LR) e/ou pesos de loss.\n",
    "  2. **Exploração do espaço de projeto** (amostrar \\(\\mathbf{p}\\), avaliar com o surrogate, calcular objetivo).\n",
    "\n",
    "Abaixo implementamos a **camada 2** (busca no espaço de projeto). A camada 1 segue o mesmo padrão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205877b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_designs(model, n_candidates=1000):\n",
    "    cand = sample_design(n_candidates)\n",
    "    results = []\n",
    "    for p in cand:\n",
    "        # Monta grid de condições (das suas curvas)\n",
    "        cond_df = df_all[[c for c in df_all.columns if c.endswith('_norm') and c.replace('_norm','') in feature_cols]]\n",
    "        # Normaliza o design\n",
    "        p_norm = {k+'_norm': (p[k]-design_space[k][0])/(design_space[k][1]-design_space[k][0]) for k in design_space}\n",
    "        P = pd.DataFrame([p_norm]*len(cond_df))\n",
    "        X_eval = pd.concat([P.reset_index(drop=True), cond_df.reset_index(drop=True)], axis=1)\n",
    "        X_eval_t = torch.tensor(X_eval.values, dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():\n",
    "            Y_pred = model(X_eval_t).cpu().numpy()\n",
    "        # Desnormaliza previsões\n",
    "        pred = {}\n",
    "        for j, name in enumerate([c for c in target_cols if c+'_norm' in df_all.columns]):\n",
    "            mn, mx = norm_stats[name]['min'], norm_stats[name]['max']\n",
    "            pred[name] = Y_pred[:, j]*(mx - mn) + mn\n",
    "        score = objective_scalar(pred)\n",
    "        results.append({'params': p, 'score': score})\n",
    "    results = sorted(results, key=lambda d: d['score'])\n",
    "    return results\n",
    "\n",
    "if X is not None:\n",
    "    ranked = evaluate_designs(model, n_candidates=200)  # aumente para 1000+ conforme compute\n",
    "    ranked[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd4bec",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Exportar o melhor resultado e métricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fae9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'runs_generic'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(outdir, 'surrogate_best.pt'))\n",
    "with open(os.path.join(outdir, 'top_designs.json'), 'w') as f:\n",
    "    json.dump(ranked[:20], f, indent=2)\n",
    "print('Arquivos salvos em:', outdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0dcc5",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Visualizações rápidas\n",
    "\n",
    "> Observação: ao fazer gráficos, usamos **matplotlib** e **um único gráfico por figura**, sem estilos/cores específicas, conforme diretrizes deste ambiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curve(x, y, xlabel='condição', ylabel='coeficiente', title='Curva prevista'):\n",
    "    plt.figure()\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(xlabel); plt.ylabel(ylabel); plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo: plota Cd previsto do melhor design para as condições do dataset\n",
    "if X is not None:\n",
    "    best = ranked[0]['params']\n",
    "    cond_df = df_all[[c for c in df_all.columns if c.endswith('_norm') and c.replace('_norm','') in feature_cols]]\n",
    "    p_norm = {k+'_norm': (best[k]-design_space[k][0])/(design_space[k][1]-design_space[k][0]) for k in design_space}\n",
    "    P = pd.DataFrame([p_norm]*len(cond_df))\n",
    "    X_eval = pd.concat([P.reset_index(drop=True), cond_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Corrige reset_index param name for pandas versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_t = torch.tensor(X_eval.values, dtype=torch.float32, device=device)\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_eval_t).cpu().numpy()\n",
    "\n",
    "if 'Cd' in target_cols and 'Cd_norm' in df_all.columns:\n",
    "    x_real = df_all[feature_cols[0]].values  # assume 1D condição para plot simples\n",
    "    j = [c for c in target_cols if c+'_norm' in df_all.columns].index('Cd')\n",
    "    mn, mx = norm_stats['Cd']['min'], norm_stats['Cd']['max']\n",
    "    cd_real = Y_pred[:, j]*(mx - mn) + mn\n",
    "    plot_curve(x_real, cd_real, xlabel=feature_cols[0], ylabel='Cd', title='Cd (previsto)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b7f35",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notas finais\n",
    "- Este caderno é um **template**. O *termo físico* deve ser adaptado a um problema **seguro** (ex.: conservação de massa/energia em dutos, estabilidade de perfis civis, etc.).  \n",
    "- Para **varredura de hiperparâmetros** do surrogate, crie laços externos variando `width`, `depth`, `lr` e pesos da *loss*.  \n",
    "- Para rodadas grandes (1000+), use **checkpointing**, **seed fixo** e, se possível, aceleração por GPU/TPU.\n",
    "\n",
    "**Foco sempre em aplicações civis/educacionais.**\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
